{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagerank\n",
    "\n",
    "These bits of code were run on a local machine to reduce latency while testing\n",
    "to ensure that I had a properly functioning algorithm before running it on the\n",
    "cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Importing a bunch of libraries and setting up the directory to read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "directory_path = 'html/'\n",
    "\n",
    "# read files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "files = files\n",
    "\n",
    "print(f'Found {len(files)} files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlinks\n",
    "\n",
    "Generating an adjacency matrix consisting of outlinks from each page.\n",
    "Saves to a file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating outlinks...\n",
      "This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3137.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# an adjacency matrix of outlinks\n",
    "outlinks = np.zeros((len(files), len(files)))\n",
    "\n",
    "print('Generating outlinks...')\n",
    "print('This may take a while...')\n",
    "\n",
    "for file in tqdm(files):\n",
    "    # fetch the filename, which is the page title, which is everything before the .html\n",
    "    filename = int(file.split('.')[0])\n",
    "\n",
    "    # read each file in the directory\n",
    "    with open(os.path.join(directory_path, file), 'r') as f:\n",
    "        # use regex to parse for <a> tags with href; if a link is \n",
    "        # <a HREF='1000.html'>1000</a>, then the regex should return 1000\n",
    "        regex = re.compile(r'<a HREF=\"(\\d+).html\">')\n",
    "\n",
    "        # read the file\n",
    "        html = f.read()\n",
    "\n",
    "        # parse the html\n",
    "        links = re.findall(regex, html)\n",
    "\n",
    "        # for each link, add an edge from the current page to the linked page\n",
    "        for link in links:\n",
    "            outlinks[filename, int(link)] = 1\n",
    "\n",
    "        # close the file\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inlinks\n",
    "\n",
    "Generating an adjacency matrix consisting of inlinks to each page.\n",
    "Saves to a file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating inlinks...\n",
      "This may take a while...\n"
     ]
    }
   ],
   "source": [
    "inlinks = np.zeros((len(files), len(files)))\n",
    "\n",
    "print('Generating inlinks...')\n",
    "print('This may take a while...')\n",
    "\n",
    "# generate inlinks from outlinks\n",
    "inlinks = outlinks.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Uses the previously generated adjacency matrices to generate some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlinks\n",
      "---\n",
      "Average number of outlinks: 122.6403\n",
      "Median number of outlinks: 123.0\n",
      "Max number of outlinks: 249.0\n",
      "Min number of outlinks: 0.0\n",
      "Quintiles: [ 49.  98. 147. 196. 249.]\n",
      "\n",
      "Inlinks\n",
      "---\n",
      "Average number of inlinks: 122.6403\n",
      "Median number of inlinks: 123.0\n",
      "Max number of inlinks: 188.0\n",
      "Min number of inlinks: 82.0\n",
      "Quintiles: [113. 120. 125. 132. 188.]\n"
     ]
    }
   ],
   "source": [
    "print('Outlinks')\n",
    "print('---')\n",
    "print(f'Average number of outlinks: {np.mean(np.sum(outlinks, axis=1))}')\n",
    "print(f'Median number of outlinks: {np.median(np.sum(outlinks, axis=1))}')\n",
    "print(f'Max number of outlinks: {np.max(np.sum(outlinks, axis=1))}')\n",
    "print(f'Min number of outlinks: {np.min(np.sum(outlinks, axis=1))}')\n",
    "print(f'Quintiles: {np.quantile(np.sum(outlinks, axis=1), [0.2, 0.4, 0.6, 0.8, 1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "print('Inlinks')\n",
    "print('---')\n",
    "print(f'Average number of inlinks: {np.mean(np.sum(inlinks, axis=1))}')\n",
    "print(f'Median number of inlinks: {np.median(np.sum(inlinks, axis=1))}')\n",
    "print(f'Max number of inlinks: {np.max(np.sum(inlinks, axis=1))}')\n",
    "print(f'Min number of inlinks: {np.min(np.sum(inlinks, axis=1))}')\n",
    "print(f'Quintiles: {np.quantile(np.sum(inlinks, axis=1), [0.2, 0.4, 0.6, 0.8, 1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank Proper\n",
    "\n",
    "The actual pagerank algorithm. Compared the bespoke pagerank implementation I\n",
    "created to the one provided by networkx to ensure that they produced the same\n",
    "results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bespoke pagerank...\n",
      "Top 5 pages with highest page rank:\n",
      "---\n",
      "Page 2526: 0.00023818080090778595\n",
      "Page 6846: 0.0002151123617518785\n",
      "Page 5971: 0.00020964002178713986\n",
      "Page 5778: 0.00020818389928806393\n",
      "Page 1058: 0.00020662190926790968\n",
      "\n",
      "Running networkx pagerank...\n",
      "Top 5 pages with highest page rank:\n",
      "---\n",
      "Page 2526: 0.00023739511425470102\n",
      "Page 6846: 0.0002152817763876744\n",
      "Page 5971: 0.00020969301369874892\n",
      "Page 5778: 0.00020816606740384702\n",
      "Page 1058: 0.0002062924071280942\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def pagerank(A, d=0.85, tol=0.005):\n",
    "    num_nodes = A.shape[0]\n",
    "    prev_pagerank = np.zeros(num_nodes) / num_nodes\n",
    "    error = 1.0\n",
    "\n",
    "    incoming_edges = [np.where(A[:, i] == 1)[0] for i in range(num_nodes)]\n",
    "    outgoing_edges = [A[i].sum(axis=1) for i in incoming_edges]\n",
    "\n",
    "    while error > tol:\n",
    "        current_pagerank = prev_pagerank.copy()\n",
    "\n",
    "        # calculate pagerank for each node\n",
    "        current_pagerank = (1 - d) + d * np.array([np.sum(current_pagerank[incoming_edges[i]] / outgoing_edges[i]) for i in range(num_nodes)])\n",
    "\n",
    "        error = np.linalg.norm(current_pagerank - prev_pagerank)\n",
    "        prev_pagerank = current_pagerank\n",
    "\n",
    "    # normalize by the sum of pageranks\n",
    "    prev_pagerank /= np.sum(prev_pagerank)\n",
    "\n",
    "    return prev_pagerank\n",
    "\n",
    "print(\"Running bespoke pagerank...\")\n",
    "p = pagerank(outlinks)\n",
    "\n",
    "# get the top 5 pages with highest page rank and their index\n",
    "top_5 = sorted(range(len(p)), key=lambda i: p[i], reverse=True)[:5]\n",
    "print(\"Top 5 pages with highest page rank:\")\n",
    "print(\"---\")\n",
    "for page in top_5:\n",
    "    print(f\"Page {page}: {p[page]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# run page rank using networkx\n",
    "print(\"Running networkx pagerank...\")\n",
    "\n",
    "G = nx.DiGraph(outlinks)\n",
    "p = nx.pagerank(G, alpha=0.85)\n",
    "\n",
    "# get top 5 pages with highest page rank\n",
    "top_5 = sorted(p.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 pages with highest page rank:\")\n",
    "print(\"---\")\n",
    "for page in top_5:\n",
    "    print(f\"Page {page[0]}: {page[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
